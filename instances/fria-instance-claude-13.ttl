@prefix fria: <http://www.example.org/fria-report#> .
@prefix airo: <https://w3id.org/airo#> .
@prefix vair: <https://w3id.org/vair#> .
@prefix cids: <http://www.example.org/cids#> .
@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .
@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .
@prefix owl: <http://www.w3.org/2002/07/owl#> .
@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .

fria:FRIA-report-ai-converts-asian-american-to-caucasian a fria:FRIA-report ;
    fria:hasReportName "AI converts Asian-American student into Caucasian" ;
    fria:hasOrganisationPositionDescription "Playground AI, an AI image generation company" ;
    fria:hasContributorDetails "Rona Wang (MIT student), Suhail Doshi (Playground AI founder)" ;
    fria:hasAssessmentContent "Playground AI's text-to-image generator changed the face of Asian-American MIT student Rona Wang into a Caucasian appearance when asked to create 'a professional LinkedIn profile photo'. The incident raised concerns about racial bias in AI systems and their potential impact on perpetuating stereotypes." ;
    fria:hasTechnologyAndDataDescription "Text-to-image generation, Generative Adversarial Networks (GANs), neural networks, deep learning, machine learning" ;
    fria:hasPurposesAndContextDescription "To generate professional-looking profile images based on user input" ;
    fria:reportDate "2023-10-10"^^xsd:date ;
    fria:hasAIAAICLink "https://www.aiaaic.org/aiaaic-repository/ai-algorithmic-and-automation-incidents/ai-converts-asian-american-student-into-caucasian" .

fria:FRIA-reportChallenge11 a fria:FRIA-reportChallenge ;
    fria:FRIA-reporthasEvaluation fria:FRIA-reportEvaluation11 ;
    fria:FRIA-reporthasImpactLevel fria:FRIA-reportImpactLevel11 ;
    rdfs:comment "The AI system does not communicate that a decision/advice or outcome is the result of an algorithmic decision" ;
    rdfs:subClassOf fria:FRIA-reportChallenge1 ;
    owl:equivalentClass airo:Transparency, vair:OperatingCriticalDigitalInfrastructure .

fria:FRIA-reportEvaluation11 a fria:FRIA-reportEvaluation ;
    fria:hasEvaluationContent "Playground AI did not clearly communicate to users that the generated image was a result of algorithmic decision-making, potentially misleading users about the nature and limitations of the output." .

fria:FRIA-reportImpactLevel11 a fria:FRIA-reportImpactLevel ;
    fria:hasImpactLevelContent "High" .

fria:FRIA-reportChallenge12 a fria:FRIA-reportChallenge ;
    fria:FRIA-reporthasEvaluation fria:FRIA-reportEvaluation12 ;
    fria:FRIA-reporthasImpactLevel fria:FRIA-reportImpactLevel12 ;
    rdfs:comment "The AI system does not provide percentages or other indication on the degree of likelihood that the outcome is correct/incorrect, prejudicing the user that there is no possibility of error and therefore that the outcome is undoubtedly incriminating" ;
    rdfs:subClassOf fria:FRIA-reportChallenge1 .

fria:FRIA-reportEvaluation12 a fria:FRIA-reportEvaluation ;
    fria:hasEvaluationContent "The system did not provide any indication of confidence levels or potential for bias in its generated images, leading users to potentially accept the racially altered output as a valid interpretation of 'professional'." .

fria:FRIA-reportImpactLevel12 a fria:FRIA-reportImpactLevel ;
    fria:hasImpactLevelContent "Very High" .

fria:FRIA-reportChallenge13 a fria:FRIA-reportChallenge ;
    fria:FRIA-reporthasEvaluation fria:FRIA-reportEvaluation13 ;
    fria:FRIA-reporthasImpactLevel fria:FRIA-reportImpactLevel13 ;
    rdfs:comment "The AI system produces an outcome that forces a reversal of burden of proof upon the suspect, by presenting itself as an absolute truth, practically depriving the defence of any chance to counter it" ;
    rdfs:subClassOf fria:FRIA-reportChallenge1 ;
    owl:equivalentClass vair:DetectingEmotionalState .

fria:FRIA-reportEvaluation13 a fria:FRIA-reportEvaluation ;
    fria:hasEvaluationContent "The system's output implicitly suggests that a Caucasian appearance is more 'professional', placing the burden on users to question and challenge this biased representation." .

fria:FRIA-reportImpactLevel13 a fria:FRIA-reportImpactLevel ;
    fria:hasImpactLevelContent "Very High" .

fria:FRIA-reportChallenge21 a fria:FRIA-reportChallenge ;
    fria:FRIA-reporthasEvaluation fria:FRIA-reportEvaluation21 ;
    fria:FRIA-reporthasImpactLevel fria:FRIA-reportImpactLevel21 ;
    rdfs:comment "The AI system targets members of a specific social group" ;
    rdfs:subClassOf fria:FRIA-reportChallenge2 ;
    owl:equivalentClass airo:PrivateService, vair:ControllingSafetyOfRoadTrafficManagement .

fria:FRIA-reportEvaluation21 a fria:FRIA-reportEvaluation ;
    fria:hasEvaluationContent "The system demonstrated clear bias against Asian-American appearances, effectively discriminating against this demographic by associating 'professional' with Caucasian features." .

fria:FRIA-reportImpactLevel21 a fria:FRIA-reportImpactLevel ;
    fria:hasImpactLevelContent "Very High" .

fria:FRIA-reportChallenge31 a fria:FRIA-reportChallenge ;
    fria:FRIA-reporthasEvaluation fria:FRIA-reportEvaluation31 ;
    fria:FRIA-reporthasImpactLevel fria:FRIA-reportImpactLevel31 ;
    rdfs:comment "There is no mechanism to limit the deployment of the AI system to suspected individuals" ;
    rdfs:subClassOf fria:FRIA-reportChallenge3 .

fria:FRIA-reportEvaluation31 a fria:FRIA-reportEvaluation ;
    fria:hasEvaluationContent "The system is deployed for general use without mechanisms to prevent its application in scenarios where racial bias could have significant negative impacts, such as job applications or professional networking." .

fria:FRIA-reportImpactLevel31 a fria:FRIA-reportImpactLevel ;
    fria:hasImpactLevelContent "High" .

fria:FRIA-reportChallenge41 a fria:FRIA-reportChallenge ;
    fria:FRIA-reporthasEvaluation fria:FRIA-reportEvaluation41 ;
    fria:FRIA-reporthasImpactLevel fria:FRIA-reportImpactLevel41 ;
    rdfs:comment "There are no mechanisms for the user to exercise control over the processing of personal data" ;
    rdfs:subClassOf fria:FRIA-reportChallenge4 .

fria:FRIA-reportEvaluation41 a fria:FRIA-reportEvaluation ;
    fria:hasEvaluationContent "Users have limited control over how their personal images are processed and transformed by the system, with no apparent option to maintain racial characteristics." .

fria:FRIA-reportImpactLevel41 a fria:FRIA-reportImpactLevel ;
    fria:hasImpactLevelContent "High" .

fria:FRIA-reportChallenge45 a fria:FRIA-reportChallenge ;
    fria:FRIA-reporthasEvaluation fria:FRIA-reportEvaluation45 ;
    fria:FRIA-reporthasImpactLevel fria:FRIA-reportImpactLevel45 ;
    rdfs:comment "There are no specific measures in place to enhance the security of the processing of personal data (via encryption, anonymisation and aggregation)" ;
    rdfs:subClassOf fria:FRIA-reportChallenge4 ;
    owl:equivalentClass vair:ApplyingTheLawToFacts .

fria:FRIA-reportEvaluation45 a fria:FRIA-reportEvaluation ;
    fria:hasEvaluationContent "The report does not mention any specific security measures for protecting the personal images uploaded by users or the generated outputs." .

fria:FRIA-reportImpactLevel45 a fria:FRIA-reportImpactLevel ;
    fria:hasImpactLevelContent "Medium" .

fria:FRIA-reportChallenge46 a fria:FRIA-reportChallenge ;
    fria:FRIA-reporthasEvaluation fria:FRIA-reportEvaluation46 ;
    fria:FRIA-reporthasImpactLevel fria:FRIA-reportImpactLevel46 ;
    rdfs:comment "There is no procedure to conduct a data protection impact assessment" ;
    rdfs:subClassOf fria:FRIA-reportChallenge4 ;
    owl:equivalentClass airo:Monitoring .

fria:FRIA-reportEvaluation46 a fria:FRIA-reportEvaluation ;
    fria:hasEvaluationContent "There is no mention of Playground AI conducting a data protection impact assessment for their image generation system, which could have identified potential issues like racial bias." .

fria:FRIA-reportImpactLevel46 a fria:FRIA-reportImpactLevel ;
    fria:hasImpactLevelContent "High" .